# Neurohackademy 2019 project directory

This repository contains descriptions of, and links to, all projects created by participants at [Neurohackademy](http://neurohackademy.org) 2019. If you're adding a new project, please use the template below.

## List of projects
* [Project template](#project-template): Template to use when creating new projects


### Project template
When adding a new project to the listing, please copy and paste the template below.


### ProjectName
**Project url(s)**: [link to GitHub repo or other resources]\
**Contributors**: [list of people involved], [NAME](https://github.com/GITHUBID)\
**Description of project**: [a few sentences describing the project]\
**How to get involved**: [optional explanation of how one can get involved in the project]

## Projects

### Neurohackmap

**Project url(s)**: https://github.com/g14r/neurohackmap \
**Contributors**: Antonija Kolobaric, Giacomo Ariani, Hannah Coyle, Johnny Lau, Daria Proklova\
**Description of project**: Neurohackmap is a collection of scripts to visualize the change in NHA19 participants' world locations and research interests over time.\
**How to get involved**: For any help in code optimization, and/or to add alternative data visualizations, pull requests are welcome. Please get in touch with one of the contributors if you would like to request full access to the dataset.

### deGANerate

**Project url(s)**: [neurohack_dl_gan](https://github.com/jeffreydurieux/neurohack_dl_gan)\
**Contributors**: [Meltem Atay](https://github.com/meltemiatay), [Bastian David](https://github.com/bastiandavid), [Jeffrey Durieux](https://github.com/jeffreydurieux), [Alberto Lazari](https://github.com/lazaral), Steph Rossi, [Anna Truzzi](https://github.com/AnnaTruzzi), [Benjamin Wade](https://github.com/bscwade), [Suniyya A. Waraich](https://github.com/suniyya)\
**Description of project**: We are working on classifying a person's age group from an MRI scan, using deep learning techniques. At the same time, we are training a GAN that takes in young brains and makes them look old. ðŸ§ \
**How to get involved**: Say hi! ðŸ‘‹ Leave a note.

### Volume to HCP CIFTI
**Project url(s)**: [Volume to HCP surface](https://github.com/htwangtw/hcp-surface-format), 
[GIFTI API proposal](https://github.com/nipy/nibabel/issues/789)\
**Contributors**: [Hao-Ting Wang (HCP, visualisation, GIFTI)](https://github.com/htwangtw), 
[Gia H Ngo (HCP, visualisation)](https://github.com/ngohgia), 
[Chris Markiewicz (GIFTI)](https://github.com/effigies)\
**Description of project**: We want to put our preprocessed volume space data on to the HCP surface template. The goal is to have the whole workflow in Python. Due to the lack of high-level surface-based tools, we are also looking into solutions to GIFTI/CIFTI file IO and visualisation. The future goal is to provide more user-friendly tools to work with surface data in Python!\
**How to get involved**: You discuss the new GIFTI API under issues or help Gia withe the python workflow. 

### Neuropythy for Dev
**Project url(s)**: [github repo](http://github.com/mcmahonmc/neuropythy-for-dev) \ 
**Contributors**: [Maya Rosen](https://github.com/mayalrosen), [Kendra Seaman](https://github.com/klsea), [Aarti Nair](https://github.com/aartinair11), [Megan McMahon](https://github.com/mcmahonmc), [Leehyun Yoon](https://github.com/ehyun1990) \
**Description of project**: Use [neuropythy](https://github.com/noahbenson/neuropythy) to visualize developmental changes in brain structure in participants from the [HCP Lifespan Pilot Study.](https://www.humanconnectome.org/lifespan-studies) \
**Goals**: 1) Access and download HCP Lifespan Pilot Data, 2) Run HCP preprocessing pipelines using a docker container on AWS, 3) Use neuropythy to retrieve and visualize age-related differences in structural properties like cortical thickness. \
**How to get involved**: Suggestions for other types of structural analysis (gyrification, TI/T2 differences) and functional analysis (resting state, tasks) are welcome. We look forward to analyzing the HCP-D and HCP-A datasets in the near future!

